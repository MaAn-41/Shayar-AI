{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3yswLkj3_N8X",
        "outputId": "3ce12f4f-3852-47c1-c2e1-c20d86b1bd9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ipywidgets in c:\\users\\pcs\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (8.1.5)\n",
            "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\pcs\\appdata\\roaming\\python\\python310\\site-packages (from ipywidgets) (8.32.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\pcs\\appdata\\roaming\\python\\python310\\site-packages (from ipywidgets) (5.14.3)\n",
            "Requirement already satisfied: comm>=0.1.3 in c:\\users\\pcs\\appdata\\roaming\\python\\python310\\site-packages (from ipywidgets) (0.2.2)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.12 in c:\\users\\pcs\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipywidgets) (4.0.13)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in c:\\users\\pcs\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipywidgets) (3.0.13)\n",
            "Requirement already satisfied: colorama in c:\\users\\pcs\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
            "Requirement already satisfied: exceptiongroup in c:\\users\\pcs\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (1.2.2)\n",
            "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\pcs\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.50)\n",
            "Requirement already satisfied: stack_data in c:\\users\\pcs\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
            "Requirement already satisfied: jedi>=0.16 in c:\\users\\pcs\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
            "Requirement already satisfied: decorator in c:\\users\\pcs\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
            "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\pcs\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
            "Requirement already satisfied: matplotlib-inline in c:\\users\\pcs\\appdata\\roaming\\python\\python310\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
            "Requirement already satisfied: typing_extensions>=4.6 in c:\\users\\pcs\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (4.12.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\pcs\\appdata\\roaming\\python\\python310\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: wcwidth in c:\\users\\pcs\\appdata\\roaming\\python\\python310\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
            "Requirement already satisfied: executing>=1.2.0 in c:\\users\\pcs\\appdata\\roaming\\python\\python310\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\pcs\\appdata\\roaming\\python\\python310\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
            "Requirement already satisfied: pure-eval in c:\\users\\pcs\\appdata\\roaming\\python\\python310\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "TPU not found. Using GPU/CPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3.1 -> 25.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d4e63c25cf234cec88f5ed9fb5822af0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "FileUpload(value=(), accept='.csv', description='Upload')"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Step 1: Install required libraries\n",
        "!pip install tensorflow numpy\n",
        "\n",
        "# Step 2: Import libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import pandas as pd\n",
        "import io\n",
        "from google.colab import files\n",
        "\n",
        "# Step 3: Enable TPU\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    print('Running on TPU:', tpu.master())\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.TPUStrategy(tpu)\n",
        "except ValueError:\n",
        "    print('TPU not found. Using GPU/CPU.')\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "\n",
        "# Step 4: Upload and load the dataset\n",
        "uploaded = files.upload()\n",
        "uploaded_file_name = list(uploaded.keys())[0]\n",
        "print(f\"Uploaded file: {uploaded_file_name}\")\n",
        "\n",
        "df = pd.read_csv(io.BytesIO(uploaded[uploaded_file_name]))\n",
        "\n",
        "# Identify correct column\n",
        "print(\"Column names in the dataset:\", df.columns)\n",
        "poetry_column_name = df.columns[0]\n",
        "print(f\"Using column '{poetry_column_name}' for poetry data.\")\n",
        "\n",
        "# Preprocess poetry data\n",
        "poetry_data = df[poetry_column_name].dropna().astype(str).tolist()\n",
        "\n",
        "# Step 5: Tokenization\n",
        "tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n')  # Remove punctuation\n",
        "tokenizer.fit_on_texts(poetry_data)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Convert text to sequences\n",
        "input_sequences = []\n",
        "for line in poetry_data:\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "\n",
        "# Set a longer max sequence length for better context\n",
        "max_sequence_len = 60\n",
        "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre')\n",
        "\n",
        "# Split input (X) and output (y)\n",
        "X = input_sequences[:, :-1]\n",
        "y = input_sequences[:, -1]\n",
        "\n",
        "# Convert y to categorical\n",
        "y = tf.keras.utils.to_categorical(y, num_classes=total_words)\n",
        "\n",
        "# Step 6: Build an improved LSTM model\n",
        "with strategy.scope():\n",
        "    model = Sequential([\n",
        "        Embedding(total_words, 300, input_length=max_sequence_len-1),  # Larger embedding\n",
        "        Bidirectional(LSTM(512, return_sequences=True)),  # Bidirectional LSTM\n",
        "        Dropout(0.3),\n",
        "        LSTM(256),  # Second LSTM layer\n",
        "        Dense(total_words, activation='softmax')  # Softmax for word prediction\n",
        "    ])\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Step 7: Train the model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=3, min_lr=1e-6)\n",
        "\n",
        "model.fit(X, y, epochs=100, batch_size=512, callbacks=[early_stopping, reduce_lr], verbose=1)\n",
        "\n",
        "# Step 8: Implement Beam Search for Poetry Generation\n",
        "def beam_search_predictions(seed_text, next_words, max_sequence_len, beam_width=3):\n",
        "    seed_text = seed_text.lower()\n",
        "    sequences = [(seed_text, 1.0)]  # Initialize with base sequence\n",
        "\n",
        "    for _ in range(next_words):\n",
        "        all_candidates = []\n",
        "        for seq, score in sequences:\n",
        "            token_list = tokenizer.texts_to_sequences([seq])[0]\n",
        "            token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\n",
        "            preds = model.predict(token_list, verbose=0)[0]\n",
        "            top_indices = np.argsort(preds)[-beam_width:]  # Get top `beam_width` words\n",
        "\n",
        "            for word_index in top_indices:\n",
        "                new_seq = seq + \" \" + tokenizer.index_word.get(word_index, \"\")\n",
        "                new_score = score * preds[word_index]\n",
        "                all_candidates.append((new_seq, new_score))\n",
        "\n",
        "        # Select the best sequences based on score\n",
        "        sequences = sorted(all_candidates, key=lambda x: x[1], reverse=True)[:beam_width]\n",
        "\n",
        "    return sequences[0][0]  # Return the best sequence\n",
        "\n",
        "# Step 9: Generate a full ghazal\n",
        "def generate_ghazal(seed_text, num_couplets, max_sequence_len, beam_width=3):\n",
        "    ghazal = []\n",
        "    used_lines = set()\n",
        "\n",
        "    for _ in range(num_couplets):\n",
        "        couplet = []\n",
        "        for _ in range(2):  # Two-line couplet\n",
        "            line = beam_search_predictions(seed_text, next_words=10, max_sequence_len=max_sequence_len, beam_width=beam_width)\n",
        "            while line in used_lines:  # Avoid repetition\n",
        "                line = beam_search_predictions(seed_text, next_words=10, max_sequence_len=max_sequence_len, beam_width=beam_width)\n",
        "            used_lines.add(line)\n",
        "            couplet.append(line)\n",
        "            seed_text = line.split()[-1]  # Use last word as new seed\n",
        "        ghazal.append(\"\\n\".join(couplet))\n",
        "\n",
        "    return \"\\n\\n\".join(ghazal)\n",
        "\n",
        "# Step 10: Get user input and generate ghazal\n",
        "seed_text = input(\"Enter a seed word (e.g., 'dil'): \")\n",
        "num_couplets = int(input(\"Enter the number of couplets to generate: \"))\n",
        "\n",
        "generated_ghazal = generate_ghazal(seed_text, num_couplets, max_sequence_len)\n",
        "\n",
        "print(\"\\nGenerated Ghazal:\\n\")\n",
        "print(generated_ghazal)\n",
        "\n",
        "# Step 11: Save the improved model\n",
        "model.save(\"shairi_generator_v2.h5\")\n",
        "print(\"\\nModel saved as 'shairi_generator_v2.h5'\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
